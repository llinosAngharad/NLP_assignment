<0.13.10.92.16.41.26.tmeadows@resumix.portal.com (tim meadows).0>
type:     cmu.cs.robotics
who:      <speaker>gregory d. hager </speaker>- 
          department of computer science
          yale university
topic:    techniques for task-directed sensor data 
          fusion and sensor planning
dates:    16-oct-92
time:     <stime>3:30 </stime>- <etime>5:00 pm</etime>
place:    <location>doherty hall 2315 (*note room*)</location>
postedby: tmeadows on 13-oct-92 at 16:41 from resumix.portal.com (tim meadows)
abstract: 

<paragraph>ri seminar</paragraph>

 when:		friday, 16 ocotober 1992, <stime>3:30 </stime>- <etime>5:00 pm</etime>
		refreshments to be served by 3:15 pm

 where:		<location>doherty hall 2315 (*note room*)</location>

 speaker:		<speaker>gregory d. hager </speaker>- 
 		department of computer science
 	 	yale university

 title:		techniques for task-directed sensor data 
 		fusion and sensor planning

<paragraph><sentence>the growing popularity of flexible, high-bandwidth sensing in robotic systems has posed many new problems for the control of sensors and sensor information processing.</sentence>  <sentence>my approach to these problems assumes that the objective of sensing is to minimize effort while maximizing the likelihood of a good or correct decision.</sentence>  <sentence>in general, any further quantification of the latter depends heavily on the specifics of a given robot task, so i refer to this approach as ``task-directed'' sensing.</sentence></paragraph>

<paragraph><sentence>this talk describes and compares two complementary approaches to solving task-directed sensing problems.</sentence>  <sentence>the first approach employs decision-theoretic methods for quantifying the value of sensor information, and relies on a novel, grid-based approximation to bayes' theorem for combining information and representing uncertainty.</sentence>  <sentence>i describe the application of these methods to a tracking-based vision system with controllable focus of attention and briefly present some experimental results.</sentence></paragraph>

<paragraph><sentence>the second approach employs a set-based representation of uncertainty.</sentence> <sentence>rather than optimizing a statistical criterion, the goal of this method is to satisfy a system of inequality constraints that represent both sensor information and task-specific decision criteria.</sentence>  <sentence>while doing so, the system adapts its data processing and data representation to the available sensor data and decision criteria.</sentence>  i show several examples, taken from the manipulation domain, where adding task constraints to the sensing probl</paragraph>

<paragraph><sentence>em significantly improves processing performance.</sentence>  <sentence>in situations where multiple objects are present, this adaptation leads to a natural, task-directed, focus-of-attention mechanism.</sentence></paragraph>

<paragraph><sentence>finally, depending on time and interest, i will briefly discuss work on generalizing set-based methods to unstructured environments, and also outline recent work in sensor planning for controlling actions.</sentence></paragraph>

<sentence>hosted by:  hagen schempf,  x6884

****************|**************************|**************************
*               |                          |                         *
*tim meadows    |  field robotics center   | carnegie mellon univ.</sentence>   *
*               |                          |                         *
*412-268-7085   |  fax: 412-682-1793       | tmeadows@frc.ri.cmu.edu *
*               |                          |                         *
**********************************************************************